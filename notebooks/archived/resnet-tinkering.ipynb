{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Resnet Tinkering\n",
    "I am trying to get the following logic to work for a resnet:\n",
    "- Give a series of input tiles\n",
    "- Add trainable layers to a pretrained Resnet-50 neural network\n",
    "- To output a feature vector\n",
    "\n",
    "This feature vector will be used as an input into a linear regression model.\n",
    "... this might change given notes in transfer learning walkthrough below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.utils import img_to_array\n",
    "from keras.utils.image_dataset import image_dataset_from_directory\n",
    "\n",
    "# TODO: Figure out which resnet is the best\n",
    "from keras.applications import ResNet50V2\n",
    "from keras.applications.resnet import preprocess_input\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:21:44.222468400Z",
     "start_time": "2023-06-27T05:21:44.216466800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First Dummy Example\n",
    "Using the Keras [transfer learning](https://keras.io/guides/transfer_learning/) walk through, I want to do some transfer learning with a Resnet model trained for image net.\n",
    "\n",
    "Also making use of [Keras applications](https://keras.io/api/applications/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Download [public dataset](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs)\n",
    "train_ds, validation_ds, test_ds = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    # Reserve 10% for validation and 10% for test\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\n",
    "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
    "print(\n",
    "    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds)\n",
    ")\n",
    "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:07:13.008633600Z",
     "start_time": "2023-06-27T05:04:35.843203300Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Plot the first 9 images in training dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:09:07.956726300Z",
     "start_time": "2023-06-27T05:09:06.486487300Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standardise data\n",
    " - Fixed tile size (this would be handled by my tiling)\n",
    " - Normalise pixel values between -1 and 1 ... need to figure this out\n",
    "\n",
    "**Interesting** - model should handle preprocessing and accept raw data as input (otherwise preprocessing would need to be done outside of model - e.g. on someone's phone). In a real-world application, this could be handled on a server though?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Resizing\n",
    "## Handled in data pipeline because \"deep neural network can only process contiguous batches of data\"\n",
    "## - contiguous means, together in a sequence\n",
    "## if we were to resize in neural network, individual tiles would need to be created (whole batch cannot be resized at once)\n",
    "## This would severely limit ability to pass batches of data through the network I think\n",
    "size = (150, 150)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:18:18.403541300Z",
     "start_time": "2023-06-27T05:18:18.326771900Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Now batching, caching and prefetching because this apparently optimises loading speeds\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:21:37.192797900Z",
     "start_time": "2023-06-27T05:21:37.147280400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Augmentation\n",
    "Introducing new samples by applying realistic transformations to training images (e.g. flipping or rotations)\n",
    "- \"exposes the model to different aspects of the training data while slowing down overfitting\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:21:48.614970800Z",
     "start_time": "2023-06-27T05:21:48.596972900Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.title(int(labels[0]))\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:21:51.742119400Z",
     "start_time": "2023-06-27T05:21:50.571609300Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building Model\n",
    "The typical transfer-learning workflow is:\n",
    "1. Instantiate a base model and load pre-trained weights (e.g. from imagenet)\n",
    "2. Freeze all layers in base model (i.e. weights won't be changed when training input and output layers)\n",
    "3. Create a new model on top of output of one or several layers from the base model\n",
    "4. Train \"new\" model - ie output model - on new dataset\n",
    "\n",
    "However!!!\n",
    "In Yeh et al, they used feature extraction. Which has a slightly more lightweight workflow.\n",
    "1. Instantiate a base model and load pre-trained weights (e.g. from imagenet)\n",
    "2. Run the new dataset through pre-trained model and record output of one or more layers from base model.\n",
    "    - This is called **feature extraction**!\n",
    "3. Use the output features extracted as input into a new, smaller model\n",
    "\n",
    "For the latter case, there is a major limitation:\n",
    "- We cannot dynamically modify input data of new model during training - e.g. with data augmentation\n",
    "This is a limitation because typiccally with a transfer learning workflow, we are using it because the new dataset (e.g. my satellite tiles) has too little data to train a full model from scratch. Therefore, data augmentation is actually really NB.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "base_model = keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "# Note for above:\n",
    "# - input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with 'channels_last' data format) or (3, 224, 224) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n",
    "# TODO: Look more at input_tensor field\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "\n",
    "# Pre-trained Resnet weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(x)\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T05:36:48.528781100Z",
     "start_time": "2023-06-27T05:36:17.467386100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definitions\n",
    "**batchnorm layer**\n",
    "- network layer that normalises output of one hidden layer before inputting into next hidden layer\n",
    "\n",
    "**inference**\n",
    "Evaluating and predicting (instead of training)\n",
    "\n",
    "**other**\n",
    "https://keras.io/getting_started/faq/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train top layer\n",
    "Also, remember that \"top\" means the output layer!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 1\n",
    "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-27T05:40:02.599294800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def decode_image(image):\n",
    "    image = tf.image.decode(image, channels=8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Constants\n",
    "IMAGE_SIZE = (256,256)\n",
    "IMAGE_CHANNELS=8\n",
    "SEED= random.randint(0, 10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T04:20:37.786919800Z",
     "start_time": "2023-06-26T04:20:37.779941100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "train_path = '../outputs/tiled-satellite-images'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T04:20:38.192924800Z",
     "start_time": "2023-06-26T04:20:38.183926700Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Generates a `tf.data.Dataset` from image files in a directory\n",
    "# TODO: Look more at arguments - e.g. defaults for batch size, shuffle; definition of subset\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    color_mode='rgb')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T04:20:38.658934600Z",
     "start_time": "2023-06-26T04:20:38.542346100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Issues & Questions Thus Far\n",
    "\n",
    "### Channels & Resnet input format\n",
    "Resnet from Keras requires 3 channel images which means that the tiled images don't work (those are 8 channel and also tiffs).\n",
    "\n",
    "How do I go about still using the 8 channels (as is done in yeh et al)?\n",
    "\n",
    "As interim, I tried to do just rgb channels and convert to png in [geotiff-to-png](./geotiff-to-png-conversion.ipynb). But I ran into other issues there where the png looks very washed out (see colour scaling below).\n",
    "\n",
    "Resolution is also still a concern.\n",
    "\n",
    "### Normalisation\n",
    "Normalisation is done in the transfer learning step by using a rescaling layer.\n",
    "\n",
    "This should be easy to incorporate if I get the input format correct.\n",
    "\n",
    "### Colour Scaling (same as normalisation?)\n",
    "Colour scaling might be why the images look a bit weird (although I tried to account for this in the conversion in the other notebook).\n",
    "\n",
    "The Geotiff has a bit-depth of 16 unisgned bits which means that a pixel value can go anywhere from 0 to 2**16-1.\n",
    "\n",
    "Accounting for this and scaling from 0 to 255 on the RGB channels, created a very washed out image.\n",
    "\n",
    "### Data augmentation and feature extraction\n",
    "Yeh et al does feature extraction in there transfer learning approach. At the time, Keras also did not have a resnet model built in so they manually implemented a Resnet 18 architecture.\n",
    "\n",
    "In my case, I would like to use keras but then I may have the input format issues mentioned above.\n",
    "\n",
    "Also, the transfer learning tutorial does say it's better to do the typical workflow rather than the \"lightweight\" workflow but I don't know how that fits in yet to my work.\n",
    "\n",
    "### Pipeline\n",
    "https://keras.io/getting_started/intro_to_keras_for_engineers/\n",
    "\n",
    "### Optimisation\n",
    "batching, caching and prefetching\n",
    "\n",
    "\n",
    "### Question about tweaking one small thing (rather than many)\n",
    "Compared to Yeh et al's work, I am changing quite a few variables:\n",
    "- Type of data used (landsat from earth engine vs planet)\n",
    "- Resolution (as a result of type of data)\n",
    "- [In-built model](https://github.com/chrisyeh96/africa_poverty_clean/blob/e13348fbd3de4fe2cf7b1127fe5cfa07d4c96351/models/hyperspectral_resnet.py) vs Keras\n",
    "- Resnet18 vs Resnet50\n",
    "- Asset wealth indicators vs service delivery indicators (or other indicators)\n",
    "\n",
    "Should I be honing into one independent variable rather? E.g. resolution, or resnet18 vs resnet50?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
