{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E2E Pipeline RGB Basic\n",
    "Trying something different\n",
    "- Input satellite images\n",
    "- Do feature extraction without fine tuning\n",
    "- Linear regression on top of features extracted"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40ee08ea55c97344"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:36:15.136565600Z",
     "start_time": "2023-09-20T05:36:11.661873800Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import PIL\n",
    "from keras import Sequential\n",
    "from keras.src.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.src.losses import MeanSquaredError\n",
    "from keras.src.metrics import RootMeanSquaredError\n",
    "from keras.src.optimizers import Adam\n",
    "from keras.src.utils import plot_model\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Enable GPU    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d36289289856373"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found - On for CPU time!')\n",
    "else:\n",
    "    print('Found GPU at {}'.format(device_name))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:36:15.211063500Z",
     "start_time": "2023-09-20T05:36:15.136565600Z"
    }
   },
   "id": "b27c7d9df254790b",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Understand images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "611eb78771f513ec"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import glob\n",
    "path = '../outputs/tiled-satellite-images-rgb'\n",
    "\n",
    "training_img = glob.glob(f'{path}/*.png')\n",
    "print('There are {} images in the training directory'.format(len(training_img)))\n",
    "\n",
    "img_sz = {'width': list(),\n",
    "         'height': list()} # store image attributes for further analysis\n",
    "width, height = 1000, 1000\n",
    "\n",
    "for im in training_img:\n",
    "    print(im)\n",
    "    img = PIL.Image.open(im)\n",
    "    w, h = img.size\n",
    "    if w < width:\n",
    "        width = w\n",
    "    if h < height:\n",
    "        height = h\n",
    "\n",
    "IMG_WIDTH = width\n",
    "IMG_HEIGHT = height\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "print('Min training image width: {} px'.format(IMG_WIDTH))\n",
    "print('Min training image height: {} px'.format(IMG_HEIGHT))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:36:15.526557100Z",
     "start_time": "2023-09-20T05:36:15.167566800Z"
    }
   },
   "id": "30024969fba31eed",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading and displaying images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19ef9f7fa8bb220f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build the training dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1247dc3328775fe7"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "data_path = '../outputs/clustered-data-gauteng.csv'\n",
    "data = pd.read_csv(data_path, dtype={\"image\":\"string\"})\n",
    "\n",
    "# Use stratified sampling\n",
    "sssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "print(data.shape)\n",
    "print(data['QoLIndex_Data_Driven'].shape)\n",
    "for train_index,test_index in sssplit.split(data, data['QoLIndex_Data_Driven']):\n",
    "    training_set = data.iloc[train_index]\n",
    "    eval_set = data.iloc[test_index]\n",
    "    \n",
    "# Visually check the distribution of service_index score in training and test sets\n",
    "training_set['QoLIndex_Data_Driven'].hist(label='Training set')\n",
    "eval_set['QoLIndex_Data_Driven'].hist(label='Eval set')\n",
    "plt.title('QoLIndex_Data_Driven score distribution in training and test set')\n",
    "plt.xlabel('QoLIndex_Data_Driven score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Export training and test sets as .csv files\n",
    "training_set['filename'] = training_set['image'].apply(lambda x: f'../outputs/tiled-satellite-images-rgb/{x}.png')\n",
    "training_set[['filename', 'QoLIndex_Data_Driven']].to_csv('../outputs/hack/working/training_set.csv', header=False, index=False)\n",
    "eval_set['filename'] = eval_set['image'].apply(lambda x: f'../outputs/tiled-satellite-images-rgb/{x}.png')\n",
    "eval_set[['filename', 'QoLIndex_Data_Driven']].to_csv('../outputs/hack/working/eval_set.csv', header=False, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:20.170686Z",
     "start_time": "2023-09-20T05:44:20.051575500Z"
    }
   },
   "id": "f59fb0a01bd23f07",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "75b01b851112db39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a222fdb884a984e3"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def read_and_decode(filename, reshape_dims):\n",
    "    # Read an image file to a tensor as a sequence of bytes\n",
    "    image = tf.io.read_file(filename)\n",
    "    # Convert the tensor to a 3D uint8 tensor\n",
    "    image = tf.image.decode_png(image, channels=IMG_CHANNELS)\n",
    "    # Convert 3D uint8 tensor with values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Resize the image to the desired size\n",
    "    return tf.image.resize(image, reshape_dims)\n",
    "\n",
    "def show_image(filename):\n",
    "    image = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    plt.imshow(image.numpy())\n",
    "    plt.axis('off')\n",
    "\n",
    "def decode_csv(csv_row):\n",
    "    record_defaults = ['filename', 'service_index']\n",
    "    filename, service_index = tf.io.decode_csv(csv_row, record_defaults)\n",
    "    service_index = tf.convert_to_tensor(float(service_index), dtype=tf.float32)\n",
    "    image = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    return image, service_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:21.830601200Z",
     "start_time": "2023-09-20T05:44:21.819198400Z"
    }
   },
   "id": "28d240070f1640f8",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import training & eval datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e743d2cb33a2a1e7"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "path = '../outputs/tiled-satellite-images-rgb'\n",
    "training_img = glob.glob(f'{path}/*.png')\n",
    "rand_idx = np.random.randint(0, len(training_img)-1)\n",
    "rand_img = training_img[rand_idx]\n",
    "\n",
    "show_image(rand_img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:22.590714400Z",
     "start_time": "2023-09-20T05:44:22.432549100Z"
    }
   },
   "id": "6ecd32216ff254f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = tf.data.TextLineDataset(\n",
    "    '../outputs/hack/working/training_set.csv'\n",
    ").map(decode_csv).batch(BATCH_SIZE)\n",
    "\n",
    "eval_dataset = tf.data.TextLineDataset(\n",
    "    '../outputs/hack/working/eval_set.csv'\n",
    ").map(decode_csv).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:22.997487300Z",
     "start_time": "2023-09-20T05:44:22.934488500Z"
    }
   },
   "id": "a10082c5ec3d7a4d",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cba625a8dfeff3"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Build model\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(units=1, activation=None)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:32.964440400Z",
     "start_time": "2023-09-20T05:44:32.931680700Z"
    }
   },
   "id": "70f0c64ded29adb0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:33.569322600Z",
     "start_time": "2023-09-20T05:44:33.518323500Z"
    }
   },
   "id": "c1bd8b5e15bb00d6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": "plot_model(model, show_shapes=True, show_layer_names=False)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:34.114047700Z",
     "start_time": "2023-09-20T05:44:34.088050800Z"
    }
   },
   "id": "44a0c3db8b571bcd",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "model.compile(optimizer= Adam(),\n",
    "              loss=MeanSquaredError(),\n",
    "              metrics=[RootMeanSquaredError()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:44:34.576405700Z",
     "start_time": "2023-09-20T05:44:34.548249800Z"
    }
   },
   "id": "29db13a42213ce08",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:48:57.793676100Z",
     "start_time": "2023-09-20T05:44:35.186714800Z"
    }
   },
   "id": "7e01ed88e79334e3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def training_plot(metrics, history):\n",
    "    f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax[idx].plot(history.history[metric], ls='dashed')\n",
    "        ax[idx].set_xlabel('Epochs')\n",
    "        ax[idx].set_ylabel(metric)\n",
    "        ax[idx].plot(history.history['val_'+metric])\n",
    "        ax[idx].legend(['train_'+metric, 'val_'+metric])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:51:19.727733200Z",
     "start_time": "2023-09-20T05:51:19.701733500Z"
    }
   },
   "id": "104d5a3f900280d2",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "training_plot(['loss', 'root_mean_squared_error'], history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T05:51:21.716447800Z",
     "start_time": "2023-09-20T05:51:21.492386200Z"
    }
   },
   "id": "cc95a67cafcd693",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notes & Takeaways\n",
    "\n",
    "- I was following [this tutorial](https://www.kaggle.com/code/emilyrosesteyn/convolutional-neural-network-for-image-regression/edit) for image regression\n",
    "- The shuffle split algorithm requires more image data than what I had clustered. \n",
    "- I want to build my pipeline:\n",
    "    - Data downloading (satellite image data, GCRO data, municipal boundaries data, DHS data for SA)\n",
    "    - Module for clustering data\n",
    "    - Module for downloading satellite images for clusters\n",
    "    - Class for feature extraction/encoding - see geocolab"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93e7203c07cd9479"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
